{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1c7d78601ff54ac0aa8ffb54d492e5c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92f9befb32df402e8dd1ce4c9333b13f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_570114f381dd4a8bba8cf1ed17abd3ae",
              "IPY_MODEL_8f0320110eaa45c0be1a801d5a9a560f"
            ]
          }
        },
        "92f9befb32df402e8dd1ce4c9333b13f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "570114f381dd4a8bba8cf1ed17abd3ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_17e1f083ded2404683f7562813ec7a19",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f698d1a26c7c4671a55ae33543b25d67"
          }
        },
        "8f0320110eaa45c0be1a801d5a9a560f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7b1da468766142dfb0572517ff8d63b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/3 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_655699ab537f4b4f874bf11db7c4d379"
          }
        },
        "17e1f083ded2404683f7562813ec7a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f698d1a26c7c4671a55ae33543b25d67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b1da468766142dfb0572517ff8d63b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "655699ab537f4b4f874bf11db7c4d379": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLghoSjJ1xhf"
      },
      "source": [
        "# Install libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-jqprc70uHE"
      },
      "source": [
        "%%capture\n",
        "# Transformers installation\n",
        "! pip install transformers\n",
        "! pip install datasets\n",
        "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
        "# ! pip install git+https://github.com/huggingface/transformers.git"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hu70Ng0Eqls"
      },
      "source": [
        "# Getting the Data and Preview it\n",
        "Below we are going to load the data and show you how to create the splits. However, we don't need to split the data manually becuase I have already created the splits and stored those files seperately which you can quickly download below:\n",
        "\n",
        "https://www.kaggle.com/praveengovi/emotions-dataset-for-nlp/code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ3SoJH3fUsq"
      },
      "source": [
        "# %%capture \n",
        "# !wget https://www.dropbox.com/s/ikkqxfdbdec3fuj/test.txt\n",
        "# !wget https://www.dropbox.com/s/1pzkadrvffbqw6o/train.txt\n",
        "# !wget https://www.dropbox.com/s/2mzialpsgf9k5l3/val.txt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4rYMiOuSLWM"
      },
      "source": [
        "# with open('train.txt') as f:\n",
        "#     print(f.read()[:1000])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_03fxufWX_G"
      },
      "source": [
        "## export the datasets as txt files\n",
        "## EXERCISE: Change this to an address\n",
        "\n",
        "# train_path = \"train.txt\"\n",
        "# test_path = \"test.txt\"\n",
        "# val_path = \"val.txt\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t23zHggkEpc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed98cb1-a877-4b76-9659-422f6f836203"
      },
      "source": [
        "!wget https://www.dropbox.com/s/607ptdakxuh5i4s/merged_training.pkl"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-11 11:31:55--  https://www.dropbox.com/s/607ptdakxuh5i4s/merged_training.pkl\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/607ptdakxuh5i4s/merged_training.pkl [following]\n",
            "--2021-06-11 11:31:55--  https://www.dropbox.com/s/raw/607ptdakxuh5i4s/merged_training.pkl\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucd864c81cdc344439b57cd8b24e.dl.dropboxusercontent.com/cd/0/inline/BQM-WSp-McIp5Txb_07Y1bi9cfh7vM-S416JD_kgZBBBKPa3BvnY_XPiCK7x6HTjBkONqtE6zNuYdE2r1qxhoHGZ3IpTuArh_JIaNXkVfkFZGCF4NfrTjO8vDngZTdu8XnhWPcLEotXAwrsONGh-9sHC/file# [following]\n",
            "--2021-06-11 11:31:55--  https://ucd864c81cdc344439b57cd8b24e.dl.dropboxusercontent.com/cd/0/inline/BQM-WSp-McIp5Txb_07Y1bi9cfh7vM-S416JD_kgZBBBKPa3BvnY_XPiCK7x6HTjBkONqtE6zNuYdE2r1qxhoHGZ3IpTuArh_JIaNXkVfkFZGCF4NfrTjO8vDngZTdu8XnhWPcLEotXAwrsONGh-9sHC/file\n",
            "Resolving ucd864c81cdc344439b57cd8b24e.dl.dropboxusercontent.com (ucd864c81cdc344439b57cd8b24e.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to ucd864c81cdc344439b57cd8b24e.dl.dropboxusercontent.com (ucd864c81cdc344439b57cd8b24e.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BQPMm9VkVVKSlJVbtIC8_erzkui__H5zT8w8byDhL3LUs1urlKC7-RIZAJcqzUlPUbLkMIQWbZ3OieQA79-lbjfsVLKCsiF0Lpz1Pck7g_Xumd0kWOkPJ4bjnKvh3R_7YX53nS-4W8aY4OHsrG9_7NpCdsd07_XBzCJppdtrESQTqedV0BRgm9Vvy8GQ7qFesHH8bVnl0O8ZKK9zrMrJXJBQFpTnQ4mMs3xyUOTGH_SVea-HtSJnKhhcxOeC8BDNfb6jdU33BykEB-NailFhTTCZJA2LLrXzZF28wOGOxELTraijQdMlYr1UXRqC6YzOpREeYbTSJao7KztVRLMixlZEd2cZ0N1dqYQw6BuXf5DiN-g6sRngtH7d004spItGCqk/file [following]\n",
            "--2021-06-11 11:31:56--  https://ucd864c81cdc344439b57cd8b24e.dl.dropboxusercontent.com/cd/0/inline2/BQPMm9VkVVKSlJVbtIC8_erzkui__H5zT8w8byDhL3LUs1urlKC7-RIZAJcqzUlPUbLkMIQWbZ3OieQA79-lbjfsVLKCsiF0Lpz1Pck7g_Xumd0kWOkPJ4bjnKvh3R_7YX53nS-4W8aY4OHsrG9_7NpCdsd07_XBzCJppdtrESQTqedV0BRgm9Vvy8GQ7qFesHH8bVnl0O8ZKK9zrMrJXJBQFpTnQ4mMs3xyUOTGH_SVea-HtSJnKhhcxOeC8BDNfb6jdU33BykEB-NailFhTTCZJA2LLrXzZF28wOGOxELTraijQdMlYr1UXRqC6YzOpREeYbTSJao7KztVRLMixlZEd2cZ0N1dqYQw6BuXf5DiN-g6sRngtH7d004spItGCqk/file\n",
            "Reusing existing connection to ucd864c81cdc344439b57cd8b24e.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49991846 (48M) [application/octet-stream]\n",
            "Saving to: â€˜merged_training.pklâ€™\n",
            "\n",
            "merged_training.pkl 100%[===================>]  47.68M  80.0MB/s    in 0.6s    \n",
            "\n",
            "2021-06-11 11:31:57 (80.0 MB/s) - â€˜merged_training.pklâ€™ saved [49991846/49991846]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQrMSUTRF06B"
      },
      "source": [
        "import pickle\n",
        "\n",
        "## helper function\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGz89mNSHaYM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "1ea839ce-0643-420b-a2f2-63bdd61f4ff7"
      },
      "source": [
        "data = load_from_pickle(directory=\"merged_training.pkl\")\n",
        "\n",
        "## emotion labels\n",
        "label2int = {\n",
        "  \"sadness\": 0,\n",
        "  \"joy\": 1,\n",
        "  \"love\": 2,\n",
        "  \"anger\": 3,\n",
        "  \"fear\": 4,\n",
        "  \"surprise\": 5\n",
        "}\n",
        "\n",
        "data = data[data[\"emotions\"].isin(label2int.keys())]\n",
        "\n",
        "print(data.shape)\n",
        "\n",
        "data = data.sample(n=10000);\n",
        "\n",
        "data.emotions.value_counts().plot.bar()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(416809, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f67dfafb150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYxc8fx_H3ad"
      },
      "source": [
        "Data has been preprocessed already, using technique from this paper: https://www.aclweb.org/anthology/D18-1404/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYKK7ujRHfRt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "3085e744-222d-45b8-ddf0-a37d2b8ba78a"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28440</th>\n",
              "      <td>i just feel really helpless and heavy hearted</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120222</th>\n",
              "      <td>ive enjoyed being able to slouch about relax a...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24397</th>\n",
              "      <td>i gave up my internship with the dmrg and am f...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22002</th>\n",
              "      <td>i dont know i feel so lost</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>i am a kindergarten teacher and i am thoroughl...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions\n",
              "28440       i just feel really helpless and heavy hearted     fear\n",
              "120222  ive enjoyed being able to slouch about relax a...  sadness\n",
              "24397   i gave up my internship with the dmrg and am f...     fear\n",
              "22002                          i dont know i feel so lost  sadness\n",
              "212     i am a kindergarten teacher and i am thoroughl...     fear"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXovcl56NFPp"
      },
      "source": [
        "## reset index\n",
        "data.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSzoz9InH0Ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3602167c-f554-4554-a385-5b7b7183bfe9"
      },
      "source": [
        "## check unique emotions in the dataset\n",
        "data.emotions.unique()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['fear', 'sadness', 'love', 'joy', 'surprise', 'anger'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJm31gKShQus"
      },
      "source": [
        "## Split the data and store into individual text files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ooNxSnPiztL"
      },
      "source": [
        "## uncomment the code below to generate the text files for your train, val, and test datasets.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Creating training and validation sets using an 80-20 split\n",
        "input_train, input_val, train_labels, val_labels = train_test_split(data.text.to_list(), \n",
        "                                                                    data.emotions.map(label2int).to_numpy(), \n",
        "                                                                    # data.emotions.to_numpy(), \n",
        "                                                                    test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_val, input_test, val_labels, test_labels = train_test_split(input_val, val_labels, test_size=0.5)\n",
        "\n",
        "\n",
        "## create a dataframe for each dataset\n",
        "# train_dataset = pd.DataFrame(data={\"text\": input_train, \"class\": train_labels})\n",
        "# val_dataset = pd.DataFrame(data={\"text\": input_val, \"class\": val_labels})\n",
        "# test_dataset = pd.DataFrame(data={\"text\": input_test, \"class\": test_labels})\n",
        "# final_dataset = {\"train\": train_dataset, \"val\": val_dataset , \"test\": test_dataset }\n",
        "\n",
        "# train_dataset.to_csv(train_path, sep=\";\",header=False, index=False)\n",
        "# val_dataset.to_csv(test_path, sep=\";\",header=False, index=False)\n",
        "# test_dataset.to_csv(val_path, sep=\";\",header=False, index=False)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CChH5iO60uHH"
      },
      "source": [
        "## Preparing the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE4WI6DL0uHI"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Define the model repo\n",
        "model_name = \"distilroberta-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8Jrawcr5lpN"
      },
      "source": [
        "train_encodings = tokenizer(input_train, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(input_val, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(input_test, truncation=True, padding=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeG8TtJX6HLV"
      },
      "source": [
        "import torch \n",
        "class EmoDataset(torch.utils.data.Dataset):\n",
        "    # def __init__(self, path):\n",
        "        # super().__init__()\n",
        "        # self.data_column = \"text\"\n",
        "        # self.class_column = \"class\"\n",
        "        # self.data = pd.read_csv(path, sep=\";\", header=None, \n",
        "        #                         names=[self.data_column, self.class_column],\n",
        "        #                         engine=\"python\")\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    # def __getitem__(self, idx):\n",
        "    #     return self.data.loc[idx, self.data_column], label2int[self.data.loc[idx, self.class_column]]\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    # def __len__(self):\n",
        "    #     return self.data.shape[0]\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBfjRqJX6oyp"
      },
      "source": [
        "train_dataset = EmoDataset(train_encodings, train_labels)\n",
        "val_dataset = EmoDataset(val_encodings, val_labels)\n",
        "test_dataset = EmoDataset(test_encodings, test_labels)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q29zPQU_0uHK"
      },
      "source": [
        "# Fine-tuning in PyTorch with the Trainer API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu_R5bLS0uHK"
      },
      "source": [
        "Since PyTorch does not provide a training loop, the ðŸ¤— Transformers library provides a `Trainer`\n",
        "API that is optimized for ðŸ¤— Transformers models, with a wide range of training options and with built-in features like\n",
        "logging, gradient accumulation, and mixed precision.\n",
        "\n",
        "First, let's define our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C4lCWyyWC8B",
        "outputId": "1d96c55e-1d2c-45b0-fa13-af44d83b4de1"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)\n",
        "\n",
        "del tokenizer\n",
        "# del model\n",
        "# del trainer\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM5az7It0uHK",
        "outputId": "046ae205-3310-4a30-e200-9b89c1643198"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, \n",
        "                                                           num_labels=len(label2int))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbOfFrLR0uHK"
      },
      "source": [
        "This will issue a warning about some of the pretrained weights not being used and some weights being randomly\n",
        "initialized. That's because we are throwing away the pretraining head of the BERT model to replace it with a\n",
        "classification head which is randomly initialized. We will fine-tune this model on our task, transferring the knowledge\n",
        "of the pretrained model to it (which is why doing this is called transfer learning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7vqv_Pyii7E"
      },
      "source": [
        "# from transformers import TrainerCallback\n",
        "\n",
        "# class PrinterCallback(TrainerCallback):\n",
        "\n",
        "#     def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "#         _ = logs.pop(\"total_flos\", None)\n",
        "#         if state.is_local_process_zero:\n",
        "#             print(logs)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPNh8DxL0uHM"
      },
      "source": [
        "which will start a training that you can follow with a progress bar, which should take a couple of minutes to complete\n",
        "(as long as you hav access to a GPU). It won't actually tell you anything useful about how well (or badly) your model\n",
        "is performing however as by default, there is no evaluation during training, and we didn't tell the\n",
        "`Trainer` to compute any metrics. Let's have a look on how to do that now!\n",
        "\n",
        "To have the `Trainer` compute and report metrics, we need to give it a `compute_metrics`\n",
        "function that takes predictions and labels (grouped in a namedtuple called `EvalPrediction`) and\n",
        "return a dictionary with string items (the metric names) and float values (the metric values).\n",
        "\n",
        "The ðŸ¤— Datasets library provides an easy way to get the common metrics used in NLP with the `load_metric` function.\n",
        "here we simply use accuracy. Then we define the `compute_metrics` function that just convert logits to predictions\n",
        "(remember that all ðŸ¤— Transformers models return the logits) and feed them to `compute` method of this metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD-Hp2-N0uHM"
      },
      "source": [
        "The compute function needs to receive a tuple (with logits and labels) and has to return a dictionary with string keys\n",
        "(the name of the metric) and float values. It will be called at the end of each evaluation phase on the whole arrays of\n",
        "predictions/labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rrszPR72r1U"
      },
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    metrics_dict = metric.compute(predictions=predictions, references=labels)\n",
        "    print('labels', len(labels), 'predictions', len(predictions))\n",
        "    metrics_dict.update({'roc_auc': roc_auc_score(labels, logits, \n",
        "                                                  average='micro', multi_class='ovr')})\n",
        "    return metrics_dict"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x94gzCkvAOeR"
      },
      "source": [
        "Then, to define our `Trainer`, we will need to instantiate a\n",
        "`TrainingArguments`. This class contains all the hyperparameters we can tune for the\n",
        "`Trainer` or the flags to activate the different training options it supports. Let's begin by\n",
        "using all the defaults, the only thing we then have to provide is a directory in which the checkpoints will be saved:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp4f1q9q0uHL"
      },
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=5,              # total number of training epochs\n",
        "    per_device_train_batch_size=64,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=50,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvq8aQVc7VXd"
      },
      "source": [
        "# trainer_output = trainer.train()"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzfkFiij1rZm",
        "outputId": "2b22b106-1b7c-4c0a-c39b-3152fd354b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "labels 1000 predictions 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-f245b31d31e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2006\u001b[0m             \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m             \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m             \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         )\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2219\u001b[0m         \u001b[0;31m# Metrics!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall_preds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall_labels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2221\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvalPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2222\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2223\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-062115658644>\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_pred)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predictions'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     metrics_dict.update({'roc_auc': roc_auc_score(labels, logits, \n\u001b[0;32m---> 14\u001b[0;31m                                                   average='micro', multi_class='ovr')})\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         return _multiclass_roc_auc_score(y_true, y_score, labels,\n\u001b[0;32m--> 383\u001b[0;31m                                          multi_class, average, sample_weight)\n\u001b[0m\u001b[1;32m    384\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         raise ValueError(\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0;34m\"Target scores need to be probabilities for multiclass \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \"roc_auc, i.e. they should sum up to 1.0 over classes\")\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa_-hpBa6VNR"
      },
      "source": [
        "# from torch.utils.data import DataLoader, Dataset\n",
        "# class EmoDataset(Dataset):\n",
        "#     def __init__(self, path):\n",
        "#         super().__init__()\n",
        "#         self.data_column = \"text\"\n",
        "#         self.class_column = \"class\"\n",
        "#         self.data = pd.read_csv(path, sep=\";\", header=None, \n",
        "#                                 names=[self.data_column, self.class_column],\n",
        "#                                 engine=\"python\")\n",
        "#         print(path)\n",
        "#         display(self.data.head(2))\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.data.loc[idx, self.data_column], label2int[self.data.loc[idx, self.class_column]]\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.data.shape[0]\n",
        "\n",
        "# import torch\n",
        "\n",
        "# class TokenizersCollateFn:\n",
        "#     def __init__(self, tokenizer):\n",
        "#         self.tokenizer = tokenizer\n",
        "\n",
        "#     def __call__(self, batch):\n",
        "#         # encoded = self.tokenizer.encode_batch([x[0] for x in batch])\n",
        "#         encoded = self.tokenizer([x[0] for x in batch], \n",
        "#                    max_length=150, padding=True, truncation=True, \n",
        "#                    return_tensors=\"pt\")\n",
        "        \n",
        "#         sequences_padded = torch.tensor([enc.ids for enc in encoded])\n",
        "#         attention_masks_padded = torch.tensor([enc.attention_mask for enc in encoded])\n",
        "#         labels = torch.tensor([x[1] for x in batch])\n",
        "        \n",
        "#         return (sequences_padded, attention_masks_padded), labels\n",
        "#         # return inputs, labels"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3FOFlT60uHP"
      },
      "source": [
        "We are almost ready to write our training loop, the only two things are missing are an optimizer and a learning rate\n",
        "scheduler. The default optimizer used by the `Trainer` is `AdamW`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjImTAbG0uHP"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9gLTV6X0uHP"
      },
      "source": [
        "Finally, the learning rate scheduler used by default it just a linear decay form the maximum value (5e-5 here) to 0:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTZuy-xJ0uHP"
      },
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDHxJSc_0uHQ"
      },
      "source": [
        "One last thing, we will want to use the GPU if we have access to one (otherwise training might take several hours\n",
        "instead of a couple of minutes). To do this, we define a `device` we will put our model and our batches on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oSZFEN50uHQ"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rkkdgkzb0uHQ"
      },
      "source": [
        "We now are ready to train! To get some sense of when it will be finished, we add a progress bar over our number of\n",
        "training steps, using the *tqdm* library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "1c7d78601ff54ac0aa8ffb54d492e5c9",
            "92f9befb32df402e8dd1ce4c9333b13f",
            "570114f381dd4a8bba8cf1ed17abd3ae",
            "8f0320110eaa45c0be1a801d5a9a560f",
            "17e1f083ded2404683f7562813ec7a19",
            "f698d1a26c7c4671a55ae33543b25d67",
            "7b1da468766142dfb0572517ff8d63b5",
            "655699ab537f4b4f874bf11db7c4d379"
          ]
        },
        "id": "lHUqkD7X0uHQ",
        "outputId": "6748cb41-ebe0-45f7-a3d1-d4e065b88879"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c7d78601ff54ac0aa8ffb54d492e5c9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-145-b86b10a2f8e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'tokenizers.Encoding'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzbrL-iN0uHQ"
      },
      "source": [
        "Note that if you are used to freezing the body of your pretrained model (like in computer vision) the above may seem a\n",
        "bit strange, as we are directly fine-tuning the whole model without taking any precaution. It actually works better\n",
        "this way for Transformers model (so this is not an oversight on our side). If you're not familiar with what \"freezing\n",
        "the body\" of the model means, forget you read this paragraph.\n",
        "\n",
        "Now to check the results, we need to write the evaluation loop. Like in the [trainer section](#trainer) we will\n",
        "use a metric from the datasets library. Here we accumulate the predictions at each batch before computing the final\n",
        "result when the loop is finished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al6LOymV0uHQ"
      },
      "source": [
        "metric= load_metric(\"accuracy\")\n",
        "model.eval()\n",
        "for batch in eval_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "metric.compute()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYpJ_E5e0uHQ"
      },
      "source": [
        "<a id='additional-resources'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blnTzjnT0uHQ"
      },
      "source": [
        "## Additional resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FK9ypom0uHQ"
      },
      "source": [
        "To look at more fine-tuning examples you can refer to:\n",
        "\n",
        "- [ðŸ¤— Transformers Examples](https://github.com/huggingface/transformers/tree/master/examples) which includes scripts\n",
        "  to train on all common NLP tasks in PyTorch and TensorFlow.\n",
        "\n",
        "- [ðŸ¤— Transformers Notebooks](https://huggingface.co/transformers/notebooks.html) which contains various notebooks and in particular one per task (look\n",
        "  for the *how to finetune a model on xxx*)."
      ]
    }
  ]
}