{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6099a1600f0f4163ab0cc014f392296b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_546150df89b6454bb3d429983fbbb876",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1a5bf25dc4ab4cf4a19e67d8e4da5ccf",
              "IPY_MODEL_2218b0ef1e584d62904d72229cb7f8c0"
            ]
          }
        },
        "546150df89b6454bb3d429983fbbb876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a5bf25dc4ab4cf4a19e67d8e4da5ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_56c0711128a4487e8aaee334b07d1868",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 480,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 480,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8c0af25471843b99db70196cc297974"
          }
        },
        "2218b0ef1e584d62904d72229cb7f8c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d8d8212ae32b41d4a89d61a44bb6b1ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 480/480 [00:00&lt;00:00, 11.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f43f17cc28d4832b0a8b999eb96ebc1"
          }
        },
        "56c0711128a4487e8aaee334b07d1868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8c0af25471843b99db70196cc297974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8d8212ae32b41d4a89d61a44bb6b1ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f43f17cc28d4832b0a8b999eb96ebc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlegBEZb/emotion_classification/blob/main/transformers_doc/tensorflow/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLghoSjJ1xhf"
      },
      "source": [
        "# Install libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-jqprc70uHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbc89d8-4c48-42e1-d4fd-d2067192a805"
      },
      "source": [
        "# %%capture\n",
        "# # Transformers installation\n",
        "! pip install transformers\n",
        "! pip install datasets\n",
        "# # To install from source instead of the last release, comment the command above and uncomment the following one.\n",
        "# # ! pip install git+https://github.com/huggingface/transformers.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.3MB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 27.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 33.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n",
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/a2/d4e1024c891506e1cee8f9d719d20831bac31cb5b7416983c4d2f65a6287/datasets-1.8.0-py3-none-any.whl (237kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.0.1)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/d2/d05466997f7751a2c06a7a416b7d1f131d765f7916698d3fdcb3a4d037e5/fsspec-2021.6.0-py3-none-any.whl (114kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: fsspec, xxhash, datasets\n",
            "Successfully installed datasets-1.8.0 fsspec-2021.6.0 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYGQ3ahIH_3U",
        "outputId": "2dfa5d4d-95b7-4445-d08a-217ccc981a5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.6.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hu70Ng0Eqls"
      },
      "source": [
        "# Getting the Data and Preview it\n",
        "Below we are going to load the data and show you how to create the splits. However, we don't need to split the data manually becuase I have already created the splits and stored those files seperately which you can quickly download below:\n",
        "\n",
        "https://www.kaggle.com/praveengovi/emotions-dataset-for-nlp/code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ3SoJH3fUsq"
      },
      "source": [
        "# %%capture \n",
        "# !wget https://www.dropbox.com/s/ikkqxfdbdec3fuj/test.txt\n",
        "# !wget https://www.dropbox.com/s/1pzkadrvffbqw6o/train.txt\n",
        "# !wget https://www.dropbox.com/s/2mzialpsgf9k5l3/val.txt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4rYMiOuSLWM"
      },
      "source": [
        "# with open('train.txt') as f:\n",
        "#     print(f.read()[:1000])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_03fxufWX_G"
      },
      "source": [
        "## export the datasets as txt files\n",
        "## EXERCISE: Change this to an address\n",
        "\n",
        "# train_path = \"train.txt\"\n",
        "# test_path = \"test.txt\"\n",
        "# val_path = \"val.txt\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t23zHggkEpc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21eb251a-42bb-460a-e2b7-0ffdaaf54699"
      },
      "source": [
        "!wget https://www.dropbox.com/s/607ptdakxuh5i4s/merged_training.pkl"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-12 19:04:36--  https://www.dropbox.com/s/607ptdakxuh5i4s/merged_training.pkl\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.18, 2620:100:6030:18::a27d:5012\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/607ptdakxuh5i4s/merged_training.pkl [following]\n",
            "--2021-06-12 19:04:36--  https://www.dropbox.com/s/raw/607ptdakxuh5i4s/merged_training.pkl\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc9e113054d58bfe7f9b1e21b4fc.dl.dropboxusercontent.com/cd/0/inline/BQR4FcNeC3ztznTuur2VvcdwnAy-SZvCrHbWIhPo7irOAuFssTQZQrkV5SotngYpLnwEk4z3Ww3yCabkm9llAad3M9KHKBNVbGTHlX0tCc3xNjzS4bbVWA7nmq27WV9Y4f8xJ9HCwL7oVcYY8Ra_WOmQ/file# [following]\n",
            "--2021-06-12 19:04:37--  https://uc9e113054d58bfe7f9b1e21b4fc.dl.dropboxusercontent.com/cd/0/inline/BQR4FcNeC3ztznTuur2VvcdwnAy-SZvCrHbWIhPo7irOAuFssTQZQrkV5SotngYpLnwEk4z3Ww3yCabkm9llAad3M9KHKBNVbGTHlX0tCc3xNjzS4bbVWA7nmq27WV9Y4f8xJ9HCwL7oVcYY8Ra_WOmQ/file\n",
            "Resolving uc9e113054d58bfe7f9b1e21b4fc.dl.dropboxusercontent.com (uc9e113054d58bfe7f9b1e21b4fc.dl.dropboxusercontent.com)... 162.125.82.15, 2620:100:6030:15::a27d:500f\n",
            "Connecting to uc9e113054d58bfe7f9b1e21b4fc.dl.dropboxusercontent.com (uc9e113054d58bfe7f9b1e21b4fc.dl.dropboxusercontent.com)|162.125.82.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BQRpQkHltyYNBot_XB0NSafKs5w1BEJlYfg-I7ilIWUniSslKv3KwHQdOHdZ1BhZb63eBYTv4MB7QeIng6V4BM9e50u8-DFo5Sgt4uw7rgupYX3oEl83Mj0Oc7DmhcOuvK0-XrtYyMos2J73dcEiYPknQ4dGAmjGkPaOAppwYPPapEHtJmDpBi6kCWiqFpl1I-vjA7NMyokYUb1MNO5IFRt30L3eZan4QGb5dWXnuV6ThTZCVoWBLnsMOv9rlJex0n9vYoJvee3Dz1TUB69tQzPmxH_P1FQwQ5BoYUF1r6f7L59F1njlllHpn0dmFpfjBAfJ2J_Bg91Ne2pxGdlKZEMjI54__KVvgPwumCgDrV4qofeEC9OFD2bNv0pLBbRJW2o/file [following]\n",
            "--2021-06-12 19:04:38--  https://uc9e113054d58bfe7f9b1e21b4fc.dl.dropboxusercontent.com/cd/0/inline2/BQRpQkHltyYNBot_XB0NSafKs5w1BEJlYfg-I7ilIWUniSslKv3KwHQdOHdZ1BhZb63eBYTv4MB7QeIng6V4BM9e50u8-DFo5Sgt4uw7rgupYX3oEl83Mj0Oc7DmhcOuvK0-XrtYyMos2J73dcEiYPknQ4dGAmjGkPaOAppwYPPapEHtJmDpBi6kCWiqFpl1I-vjA7NMyokYUb1MNO5IFRt30L3eZan4QGb5dWXnuV6ThTZCVoWBLnsMOv9rlJex0n9vYoJvee3Dz1TUB69tQzPmxH_P1FQwQ5BoYUF1r6f7L59F1njlllHpn0dmFpfjBAfJ2J_Bg91Ne2pxGdlKZEMjI54__KVvgPwumCgDrV4qofeEC9OFD2bNv0pLBbRJW2o/file\n",
            "Reusing existing connection to uc9e113054d58bfe7f9b1e21b4fc.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49991846 (48M) [application/octet-stream]\n",
            "Saving to: â€˜merged_training.pklâ€™\n",
            "\n",
            "merged_training.pkl 100%[===================>]  47.68M  11.0MB/s    in 5.4s    \n",
            "\n",
            "2021-06-12 19:04:44 (8.91 MB/s) - â€˜merged_training.pklâ€™ saved [49991846/49991846]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQrMSUTRF06B"
      },
      "source": [
        "import pickle\n",
        "\n",
        "## helper function\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGz89mNSHaYM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "db58f2b6-3937-4494-ace7-8786f6de706a"
      },
      "source": [
        "data = load_from_pickle(directory=\"merged_training.pkl\")\n",
        "\n",
        "## emotion labels\n",
        "label2int = {\n",
        "  \"sadness\": 0,\n",
        "  \"joy\": 1,\n",
        "  \"love\": 2,\n",
        "  \"anger\": 3,\n",
        "  \"fear\": 4,\n",
        "  \"surprise\": 5\n",
        "}\n",
        "\n",
        "data = data[data[\"emotions\"].isin(label2int.keys())]\n",
        "\n",
        "print(data.shape)\n",
        "\n",
        "data = data.sample(n=20000);\n",
        "\n",
        "data.emotions.value_counts().plot.bar()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(416809, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f765afd3810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYxc8fx_H3ad"
      },
      "source": [
        "Data has been preprocessed already, using technique from this paper: https://www.aclweb.org/anthology/D18-1404/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYKK7ujRHfRt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7aae953d-e3a7-4e3f-dc4b-d87f1ef68235"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24225</th>\n",
              "      <td>i don t feel like a valued customer a href htt...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9415</th>\n",
              "      <td>i am in the business of creating fictions afte...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18134</th>\n",
              "      <td>i finally break down and go off on a tangent a...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80521</th>\n",
              "      <td>i guess this series could have another season ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3619</th>\n",
              "      <td>i am disappointing i tell you and i to feel wr...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text emotions\n",
              "24225  i don t feel like a valued customer a href htt...      joy\n",
              "9415   i am in the business of creating fictions afte...      joy\n",
              "18134  i finally break down and go off on a tangent a...     love\n",
              "80521  i guess this series could have another season ...      joy\n",
              "3619   i am disappointing i tell you and i to feel wr...    anger"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXovcl56NFPp"
      },
      "source": [
        "## reset index\n",
        "data.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSzoz9InH0Ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0912655e-3a51-4271-ebc1-66ed55d4c4a8"
      },
      "source": [
        "## check unique emotions in the dataset\n",
        "data.emotions.unique()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['joy', 'love', 'anger', 'sadness', 'fear', 'surprise'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJm31gKShQus"
      },
      "source": [
        "## Split the data and store into individual text files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv9TyIZeZfQ2"
      },
      "source": [
        "# dummies = pd.get_dummies(data.emotions)\n",
        "# ohe_mapping = {i: c for i, c in enumerate(dummies.columns)}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ooNxSnPiztL"
      },
      "source": [
        "## uncomment the code below to generate the text files for your train, val, and test datasets.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Creating training and validation sets using an 80-20 split\n",
        "input_train, input_val, train_labels, val_labels = train_test_split(data.text.to_list(), \n",
        "                                                                    # dummies.values,\n",
        "                                                                    data.emotions.map(label2int).to_numpy(), \n",
        "                                                                    # data.emotions.to_numpy(), \n",
        "                                                                    test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_val, input_test, val_labels, test_labels = train_test_split(input_val, val_labels, test_size=0.5)\n",
        "\n",
        "\n",
        "## create a dataframe for each dataset\n",
        "# train_dataset = pd.DataFrame(data={\"text\": input_train, \"class\": train_labels})\n",
        "# val_dataset = pd.DataFrame(data={\"text\": input_val, \"class\": val_labels})\n",
        "# test_dataset = pd.DataFrame(data={\"text\": input_test, \"class\": test_labels})\n",
        "# final_dataset = {\"train\": train_dataset, \"val\": val_dataset , \"test\": test_dataset }\n",
        "\n",
        "# train_dataset.to_csv(train_path, sep=\";\",header=False, index=False)\n",
        "# val_dataset.to_csv(test_path, sep=\";\",header=False, index=False)\n",
        "# test_dataset.to_csv(val_path, sep=\";\",header=False, index=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CChH5iO60uHH"
      },
      "source": [
        "## Preparing the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE4WI6DL0uHI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "6099a1600f0f4163ab0cc014f392296b",
            "546150df89b6454bb3d429983fbbb876",
            "1a5bf25dc4ab4cf4a19e67d8e4da5ccf",
            "2218b0ef1e584d62904d72229cb7f8c0",
            "56c0711128a4487e8aaee334b07d1868",
            "b8c0af25471843b99db70196cc297974",
            "d8d8212ae32b41d4a89d61a44bb6b1ec",
            "4f43f17cc28d4832b0a8b999eb96ebc1"
          ]
        },
        "outputId": "ec9a5b19-a0f0-426d-fce4-8148857ea2b7"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Define the model repo\n",
        "model_name = \"distilroberta-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6099a1600f0f4163ab0cc014f392296b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=480.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8Jrawcr5lpN"
      },
      "source": [
        "train_encodings = tokenizer(input_train, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(input_val, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(input_test, truncation=True, padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeG8TtJX6HLV"
      },
      "source": [
        "import torch \n",
        "class EmoDataset(torch.utils.data.Dataset):\n",
        "    # def __init__(self, path):\n",
        "        # super().__init__()\n",
        "        # self.data_column = \"text\"\n",
        "        # self.class_column = \"class\"\n",
        "        # self.data = pd.read_csv(path, sep=\";\", header=None, \n",
        "        #                         names=[self.data_column, self.class_column],\n",
        "        #                         engine=\"python\")\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    # def __getitem__(self, idx):\n",
        "    #     return self.data.loc[idx, self.data_column], label2int[self.data.loc[idx, self.class_column]]\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        # labels = torch.tensor(self.labels[idx])\n",
        "        return item#, labels\n",
        "\n",
        "    # def __len__(self):\n",
        "    #     return self.data.shape[0]\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBfjRqJX6oyp"
      },
      "source": [
        "train_dataset = EmoDataset(train_encodings, train_labels)\n",
        "val_dataset = EmoDataset(val_encodings, val_labels)\n",
        "test_dataset = EmoDataset(test_encodings, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RFifOoY7Hsc"
      },
      "source": [
        "# Building Custom Classification head on top of LM base model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSUMm4Oq7nvR"
      },
      "source": [
        "Use Mish activiation function as in the one proposed in the original tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VDRSRsc71H2"
      },
      "source": [
        "# Use Mish activiation function as in the one proposed in the original tutorial\n",
        "# from https://github.com/digantamisra98/Mish/blob/b5f006660ac0b4c46e2c6958ad0301d7f9c59651/Mish/Torch/mish.py\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "\n",
        "@torch.jit.script\n",
        "def mish(input):\n",
        "    return input * torch.tanh(F.softplus(input))\n",
        "  \n",
        "class Mish(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return mish(input)\n",
        "\n",
        "class EmoModel(nn.Module):\n",
        "    def __init__(self, base_model, n_classes, \n",
        "                 base_model_output_size=768, dropout=0.05):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.n_classes = n_classes\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(base_model_output_size, base_model_output_size),\n",
        "            Mish(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(in_features=base_model_output_size, \n",
        "                      out_features=n_classes),\n",
        "            nn.Softmax(dim=-1) \n",
        "        )\n",
        "        \n",
        "        for layer in self.classifier:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                layer.weight.data.normal_(mean=0.0, std=0.02)\n",
        "                if layer.bias is not None:\n",
        "                    layer.bias.data.zero_()\n",
        "\n",
        "    def forward(self, inputs, *args):\n",
        "        # print(\"In Emo\")\n",
        "        # print(\"Inputs\", type(inputs), len(inputs))\n",
        "        # print(\"Inputs0\", type(inputs[0]), \"Inputs1\", type(inputs[1]))\n",
        "        # print('inputs', inputs)\n",
        "        input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "        hidden_states = self.base_model(input_ids=input_ids, \n",
        "                                        attention_mask=attention_mask)\n",
        "        # maybe do some pooling / RNNs... go crazy here!\n",
        "        \n",
        "        # use the <s> representation\n",
        "        # return self.classifier(hidden_states[0][:, 0, :])\n",
        "        return SequenceClassifierOutput(logits=self.classifier(hidden_states[0][:, 0, :]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C4lCWyyWC8B"
      },
      "source": [
        "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# print(device)\n",
        "\n",
        "# del tokenizer\n",
        "# # del model\n",
        "# # del trainer\n",
        "# torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM5az7It0uHK"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, \n",
        "                                                           num_labels=len(label2int))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjoyYHeGHQXj"
      },
      "source": [
        "emotion_model = EmoModel(base_model=model.base_model, \n",
        "                         n_classes=len(label2int)) \n",
        "\n",
        "output = emotion_model(val_dataset.__getitem__(slice(5)))\n",
        "output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z76olD6bcI54"
      },
      "source": [
        "type(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk4nCtCt2lTq"
      },
      "source": [
        "val_dataset.__getitem__(slice(5))['labels']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPq-Kf8S1-RM"
      },
      "source": [
        "loss_fct = torch.nn.NLLLoss()\n",
        "loss_fct(torch.log(output.logits), val_dataset.__getitem__(slice(5))['labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y-HvuchIbx0"
      },
      "source": [
        "len(val_dataset.__getitem__(slice(5))['input_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2vU73ugV3aZ"
      },
      "source": [
        "ds = val_dataset.__getitem__(slice(2))\n",
        "ds.pop('labels')\n",
        "list(ds.values())\n",
        "base_output = model.base_model(*list(ds.values()))\n",
        "base_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2sqB9H5Yg5-"
      },
      "source": [
        "seq_clf_output = model(*list(ds.values()))\n",
        "type(seq_clf_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcWdEjctcOeH"
      },
      "source": [
        "seq_clf_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q29zPQU_0uHK"
      },
      "source": [
        "# Fine-tuning in PyTorch with the Trainer API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu_R5bLS0uHK"
      },
      "source": [
        "Since PyTorch does not provide a training loop, the ðŸ¤— Transformers library provides a `Trainer`\n",
        "API that is optimized for ðŸ¤— Transformers models, with a wide range of training options and with built-in features like\n",
        "logging, gradient accumulation, and mixed precision.\n",
        "\n",
        "First, let's define our model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbOfFrLR0uHK"
      },
      "source": [
        "This will issue a warning about some of the pretrained weights not being used and some weights being randomly\n",
        "initialized. That's because we are throwing away the pretraining head of the BERT model to replace it with a\n",
        "classification head which is randomly initialized. We will fine-tune this model on our task, transferring the knowledge\n",
        "of the pretrained model to it (which is why doing this is called transfer learning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7vqv_Pyii7E"
      },
      "source": [
        "# from transformers import TrainerCallback\n",
        "\n",
        "# class PrinterCallback(TrainerCallback):\n",
        "\n",
        "#     def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "#         _ = logs.pop(\"total_flos\", None)\n",
        "#         if state.is_local_process_zero:\n",
        "#             print(logs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPNh8DxL0uHM"
      },
      "source": [
        "which will start a training that you can follow with a progress bar, which should take a couple of minutes to complete\n",
        "(as long as you hav access to a GPU). It won't actually tell you anything useful about how well (or badly) your model\n",
        "is performing however as by default, there is no evaluation during training, and we didn't tell the\n",
        "`Trainer` to compute any metrics. Let's have a look on how to do that now!\n",
        "\n",
        "To have the `Trainer` compute and report metrics, we need to give it a `compute_metrics`\n",
        "function that takes predictions and labels (grouped in a namedtuple called `EvalPrediction`) and\n",
        "return a dictionary with string items (the metric names) and float values (the metric values).\n",
        "\n",
        "The ðŸ¤— Datasets library provides an easy way to get the common metrics used in NLP with the `load_metric` function.\n",
        "here we simply use accuracy. Then we define the `compute_metrics` function that just convert logits to predictions\n",
        "(remember that all ðŸ¤— Transformers models return the logits) and feed them to `compute` method of this metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD-Hp2-N0uHM"
      },
      "source": [
        "The compute function needs to receive a tuple (with logits and labels) and has to return a dictionary with string keys\n",
        "(the name of the metric) and float values. It will be called at the end of each evaluation phase on the whole arrays of\n",
        "predictions/labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rrszPR72r1U"
      },
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    metrics_dict = dict()\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    print('in metrics. pred', len(predictions), 'logits', len(logits), 'labels', len(labels))\n",
        "    metrics_dict.update(metric.compute(predictions=predictions, references=labels))\n",
        "    # metrics_dict.update({'roc_auc': roc_auc_score(labels, logits, \n",
        "    #                                               average='micro', multi_class='ovr')})\n",
        "    return metrics_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x94gzCkvAOeR"
      },
      "source": [
        "Then, to define our `Trainer`, we will need to instantiate a\n",
        "`TrainingArguments`. This class contains all the hyperparameters we can tune for the\n",
        "`Trainer` or the flags to activate the different training options it supports. Let's begin by\n",
        "using all the defaults, the only thing we then have to provide is a directory in which the checkpoints will be saved:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp4f1q9q0uHL"
      },
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=5,              # total number of training epochs\n",
        "    per_device_train_batch_size=64,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=50,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# class MultilabelTrainer(Trainer):\n",
        "#     def compute_loss(self, model, inputs, return_outputs=False):\n",
        "#         labels = inputs.pop(\"labels\")\n",
        "#         outputs = model(**inputs)\n",
        "#         logits = outputs.logits\n",
        "#         loss_fct = torch.nn.BCEWithLogitsLoss()\n",
        "#         loss = loss_fct(logits.view(-1, self.model.config.num_labels),\n",
        "#                         labels.float().view(-1, self.model.config.num_labels))\n",
        "#         return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "class MultiClassTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = torch.nn.NLLLoss()\n",
        "        # loss = loss_fct(outputs.view(-1, self.model.n_classes),\n",
        "        #                 labels.float().view(-1, self.model.n_classes))\n",
        "        loss = loss_fct(torch.log(logits), labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "trainer = MultiClassTrainer(\n",
        "    # model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    model=emotion_model,\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvq8aQVc7VXd"
      },
      "source": [
        "trainer_output = trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzfkFiij1rZm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "4dbc0a1a-7a37-4beb-da73-7306b666aaab"
      },
      "source": [
        "trainer.evaluate(val_dataset)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "outputs computed: <class 'transformers.modeling_outputs.SequenceClassifierOutput'>\n",
            "output type is dict\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "outputs computed: <class 'transformers.modeling_outputs.SequenceClassifierOutput'>\n",
            "output type is dict\n",
            "in metrics. pred 100 logits 100 labels 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.15,\n",
              " 'eval_loss': 1.8483418226242065,\n",
              " 'eval_mem_cpu_alloc_delta': 34045952,\n",
              " 'eval_mem_cpu_peaked_delta': 0,\n",
              " 'eval_mem_gpu_alloc_delta': 0,\n",
              " 'eval_mem_gpu_peaked_delta': 145020928,\n",
              " 'eval_runtime': 0.4034,\n",
              " 'eval_samples_per_second': 247.899,\n",
              " 'init_mem_cpu_alloc_delta': 2575204352,\n",
              " 'init_mem_cpu_peaked_delta': 0,\n",
              " 'init_mem_gpu_alloc_delta': 329790464,\n",
              " 'init_mem_gpu_peaked_delta': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa_-hpBa6VNR"
      },
      "source": [
        "# from torch.utils.data import DataLoader, Dataset\n",
        "# class EmoDataset(Dataset):\n",
        "#     def __init__(self, path):\n",
        "#         super().__init__()\n",
        "#         self.data_column = \"text\"\n",
        "#         self.class_column = \"class\"\n",
        "#         self.data = pd.read_csv(path, sep=\";\", header=None, \n",
        "#                                 names=[self.data_column, self.class_column],\n",
        "#                                 engine=\"python\")\n",
        "#         print(path)\n",
        "#         display(self.data.head(2))\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.data.loc[idx, self.data_column], label2int[self.data.loc[idx, self.class_column]]\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.data.shape[0]\n",
        "\n",
        "# import torch\n",
        "\n",
        "# class TokenizersCollateFn:\n",
        "#     def __init__(self, tokenizer):\n",
        "#         self.tokenizer = tokenizer\n",
        "\n",
        "#     def __call__(self, batch):\n",
        "#         # encoded = self.tokenizer.encode_batch([x[0] for x in batch])\n",
        "#         encoded = self.tokenizer([x[0] for x in batch], \n",
        "#                    max_length=150, padding=True, truncation=True, \n",
        "#                    return_tensors=\"pt\")\n",
        "        \n",
        "#         sequences_padded = torch.tensor([enc.ids for enc in encoded])\n",
        "#         attention_masks_padded = torch.tensor([enc.attention_mask for enc in encoded])\n",
        "#         labels = torch.tensor([x[1] for x in batch])\n",
        "        \n",
        "#         return (sequences_padded, attention_masks_padded), labels\n",
        "#         # return inputs, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY0g7fwaM6m3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO1r-zbAM6Jv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WMyu4x4M5jy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzbrL-iN0uHQ"
      },
      "source": [
        "Note that if you are used to freezing the body of your pretrained model (like in computer vision) the above may seem a\n",
        "bit strange, as we are directly fine-tuning the whole model without taking any precaution. It actually works better\n",
        "this way for Transformers model (so this is not an oversight on our side). If you're not familiar with what \"freezing\n",
        "the body\" of the model means, forget you read this paragraph.\n",
        "\n",
        "Now to check the results, we need to write the evaluation loop. Like in the [trainer section](#trainer) we will\n",
        "use a metric from the datasets library. Here we accumulate the predictions at each batch before computing the final\n",
        "result when the loop is finished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al6LOymV0uHQ"
      },
      "source": [
        "metric= load_metric(\"accuracy\")\n",
        "model.eval()\n",
        "for batch in eval_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "metric.compute()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}